{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 21:56:10.140212: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-04 21:56:10.318859: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-04 21:56:10.988564: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-04 21:56:10.988645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-04 21:56:10.991641: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-04 21:56:11.284918: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-04 21:56:11.289789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 21:56:14.774904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "sns.set_theme(style = 'white', palette = 'viridis')\n",
    "pal = sns.color_palette('viridis')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "set_config(transform_output = 'pandas')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/kaggle/input/optiver-trading-at-the-close'\n",
    "DATA_DIR = 'input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{DATA_DIR}/train.csv').drop(['row_id', 'time_id'], axis = 1)\n",
    "test = pd.read_csv(f'{DATA_DIR}/example_test_files/test.csv').drop(['row_id', 'time_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[~train.target.isna()]\n",
    "y = X.pop('target')\n",
    "\n",
    "seed = 42\n",
    "tss = TimeSeriesSplit(10)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_calculator(x):\n",
    "    \n",
    "    x_copy = x.copy()\n",
    "    \n",
    "    x_copy['imb_s1'] = x.eval('(bid_size - ask_size) / (bid_size + ask_size)')\n",
    "    x_copy['imb_s2'] = x.eval('(imbalance_size - matched_size) / (matched_size + imbalance_size)')\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            if i>j:\n",
    "                x_copy[f'{a}_{b}_imb'] = x.eval(f'({a} - {b}) / ({a} + {b})')\n",
    "                    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            for k,c in enumerate(prices):\n",
    "                if i>j and j>k:\n",
    "                    max_ = x[[a,b,c]].max(axis=1)\n",
    "                    min_ = x[[a,b,c]].min(axis=1)\n",
    "                    mid_ = x[[a,b,c]].sum(axis=1)-min_-max_\n",
    "\n",
    "                    x_copy[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "    return x_copy\n",
    "\n",
    "ImbalanceCalculator = FunctionTransformer(imbalance_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBMRegressorCV:\n",
    "    \n",
    "    def __init__(self, params, cv = tss, n_estimators = 1000):\n",
    "        \n",
    "        self.params = params\n",
    "        self.cv = cv\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "        self.models = []\n",
    "        self.best_val_score = None\n",
    "        self.val_scores = []\n",
    "        self.train_scores = []\n",
    "        self.best_model = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        for train_index, test_index in tqdm(self.cv.split(X, y)):\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            model = LGBMRegressor(**self.params, n_estimators = self.n_estimators)\n",
    "            model.fit(X_train, y_train, eval_set = [(X_test, y_test)], eval_metric='mae')\n",
    "            \n",
    "            self.models.append(model)\n",
    "            self.train_scores.append(mean_absolute_error(y_train, model.predict(X_train)))\n",
    "            self.val_scores.append(mean_absolute_error(y_test, model.predict(X_test)))\n",
    "\n",
    "        if self.best_val_score is None:\n",
    "            self.best_val_score = self.val_scores[-1]\n",
    "            self.best_model = clone(model)\n",
    "        elif self.val_scores[-1] < self.best_val_score:\n",
    "                self.best_val_score = self.val_scores[-1]\n",
    "                self.best_model = clone(model)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        # Use best model to predict\n",
    "        return self.best_model.predict(X)\n",
    "    \n",
    "    def get_best_model_params(self):\n",
    "        # Get parameters of the best model\n",
    "        return self.best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12283\n",
      "[LightGBM] [Info] Number of data points in the train set: 476172, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score -0.096914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:17, 77.67s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = make_pipeline(\n",
    "    ImbalanceCalculator, \n",
    "    LGBMRegressorCV(params = {'random_state': seed}, n_estimators = 1000))\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
