{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 0. Introduction"]},{"cell_type":"markdown","metadata":{},"source":["**Purpose of this notebook üéØ**\n","\n","This notebook aim to achieve 2 things:\n","\n","1. Explain the data in simple language, especially to those without a financial background. \n","\n","2. Provide a simple lightGBM workflow as baseline.\n","\n","This notebook assumes that you are fimilar with the submission API. I explored the API a little bit in my another notebook:\n","\n","[Understand the Submission APIüïµÔ∏è](https://www.kaggle.com/code/a27182818/understand-the-submission-api)\n","\n","Check it out, if you are interested!\n","\n","-----\n","\n","**Table of Contents**üìö\n","\n","- **0. Introduction**\n","\n","- **1. Explore & Explain the Data**\n","\n","    - 1.1. Understand the structure\n","\n","        - 1.1.1. A glimpse of the data\n","\n","        - 1.1.2. What type of data are missing?\n","\n","    - 1.2. Understand the features\n","\n","        - 1.2.1 Order book\n","\n","        - 1.2.2. Auction Order Book\n","\n","        - 1.2.3. Combined Book\n","\n","    - 1.3. Understand the target\n","\n","- **2. LightGBM Baseline**\n","\n","    - 2.1. Naive Baseline\n","\n","    - 2.2. Simplest LightGBM Solution\n","\n","    - 2.3. Improved LightGBM Solution\n","\n","- **3. Final Thoughts**"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# For Kaggle\n","\n","# Standard Libraries\n","import sys\n","import os\n","import collections\n","\n","# Data Science Libraries\n","import pandas as pd\n","import numpy as np\n","# import optuna\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.pylab as pylab\n","import seaborn as sns\n","\n","# Statistics Libraries\n","import statsmodels.api as sm\n","import statsmodels.tsa.api as smt\n","import statsmodels.graphics.api as smg\n","\n","# ML Libraries\n","import sklearn as sk\n","import lightgbm\n","import xgboost\n","import catboost\n","\n","# Project Libraries\n","# import optiver2023\n","\n","# Configure Visualization\n","%matplotlib inline\n","plt.style.use('bmh')\n","\n","# Configure Pandas and SKLearn\n","pd.set_option(\"display.max_colwidth\", 20)\n","pd.set_option(\"display.precision\", 3)\n","sk.set_config(display=\"diagram\")\n","\n","# File Specific Configurations\n","DATA_DIR = \"./\"\n","plt.rcParams['figure.dpi'] = 300\n","START = pd.Timestamp.now()\n","SEED = 42"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Explore & Explain the Data\n","\n","**Purpose of this section üéØ**\n","\n","- 1.1. Explore the structure of the data.\n","\n","- 1.2. Understand each **feature** intuitively.\n","\n","- 1.3. Speculate how each **feature** influence the **target**.\n","\n","**Inspiration and Credits:**\n","\n","- [Optiver - Trading At The Close Introduction](https://www.kaggle.com/code/tomforbes/optiver-trading-at-the-close-introduction) provides a nice explanation on the differences between **Order book** and **Auction order book**. They are the keys to understand the data. We incorporate some of their graphs and explanations into this notebook.\n","\n","## 1.1. Understand the structure\n","\n","### 1.1.1. A glimpse of the data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def inspect_columns(df):\n","    # A helper function that does a better job than df.info() and df.describe()\n","    result = pd.DataFrame({\n","        'unique': df.nunique() == len(df),\n","        'cardinality': df.nunique(),\n","        'with_null': df.isna().any(),\n","        'null_pct': round((df.isnull().sum() / len(df)) * 100, 2),\n","        '1st_row': df.iloc[0],\n","        'random_row': df.iloc[np.random.randint(low=0, high=len(df))],\n","        'last_row': df.iloc[-1],\n","        'dtype': df.dtypes\n","    })\n","    return result"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stock_id</th>\n","      <th>date_id</th>\n","      <th>seconds_in_bucket</th>\n","      <th>imbalance_size</th>\n","      <th>imbalance_buy_sell_flag</th>\n","      <th>reference_price</th>\n","      <th>matched_size</th>\n","      <th>far_price</th>\n","      <th>near_price</th>\n","      <th>bid_price</th>\n","      <th>bid_size</th>\n","      <th>ask_price</th>\n","      <th>ask_size</th>\n","      <th>wap</th>\n","      <th>target</th>\n","      <th>time_id</th>\n","      <th>row_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.181e+06</td>\n","      <td>1</td>\n","      <td>1.000</td>\n","      <td>1.338e+07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000</td>\n","      <td>60651.50</td>\n","      <td>1.000</td>\n","      <td>8493.03</td>\n","      <td>1.000</td>\n","      <td>-3.030</td>\n","      <td>0</td>\n","      <td>0_0_0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.666e+05</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>1.642e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000</td>\n","      <td>3233.04</td>\n","      <td>1.001</td>\n","      <td>20605.09</td>\n","      <td>1.000</td>\n","      <td>-5.520</td>\n","      <td>0</td>\n","      <td>0_0_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.029e+05</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>1.819e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>37956.00</td>\n","      <td>1.000</td>\n","      <td>18995.00</td>\n","      <td>1.000</td>\n","      <td>-8.390</td>\n","      <td>0</td>\n","      <td>0_0_2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.192e+07</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>1.839e+07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000</td>\n","      <td>2324.90</td>\n","      <td>1.000</td>\n","      <td>479032.40</td>\n","      <td>1.000</td>\n","      <td>-4.010</td>\n","      <td>0</td>\n","      <td>0_0_3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.475e+05</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>1.786e+07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>16485.54</td>\n","      <td>1.000</td>\n","      <td>434.10</td>\n","      <td>1.000</td>\n","      <td>-7.350</td>\n","      <td>0</td>\n","      <td>0_0_4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5237975</th>\n","      <td>195</td>\n","      <td>480</td>\n","      <td>540</td>\n","      <td>2.441e+06</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>2.828e+07</td>\n","      <td>1.000</td>\n","      <td>1.000</td>\n","      <td>1.000</td>\n","      <td>32257.04</td>\n","      <td>1.000</td>\n","      <td>319862.40</td>\n","      <td>1.000</td>\n","      <td>2.310</td>\n","      <td>26454</td>\n","      <td>480_540_195</td>\n","    </tr>\n","    <tr>\n","      <th>5237976</th>\n","      <td>196</td>\n","      <td>480</td>\n","      <td>540</td>\n","      <td>3.495e+05</td>\n","      <td>-1</td>\n","      <td>1.001</td>\n","      <td>9.188e+06</td>\n","      <td>1.000</td>\n","      <td>1.000</td>\n","      <td>1.001</td>\n","      <td>205108.40</td>\n","      <td>1.001</td>\n","      <td>93393.07</td>\n","      <td>1.001</td>\n","      <td>-8.220</td>\n","      <td>26454</td>\n","      <td>480_540_196</td>\n","    </tr>\n","    <tr>\n","      <th>5237977</th>\n","      <td>197</td>\n","      <td>480</td>\n","      <td>540</td>\n","      <td>0.000e+00</td>\n","      <td>0</td>\n","      <td>0.996</td>\n","      <td>1.273e+07</td>\n","      <td>0.996</td>\n","      <td>0.996</td>\n","      <td>0.996</td>\n","      <td>16790.66</td>\n","      <td>0.996</td>\n","      <td>180038.32</td>\n","      <td>0.996</td>\n","      <td>1.169</td>\n","      <td>26454</td>\n","      <td>480_540_197</td>\n","    </tr>\n","    <tr>\n","      <th>5237978</th>\n","      <td>198</td>\n","      <td>480</td>\n","      <td>540</td>\n","      <td>1.001e+06</td>\n","      <td>1</td>\n","      <td>0.999</td>\n","      <td>9.477e+07</td>\n","      <td>0.999</td>\n","      <td>0.999</td>\n","      <td>0.999</td>\n","      <td>125631.72</td>\n","      <td>0.999</td>\n","      <td>669893.00</td>\n","      <td>0.999</td>\n","      <td>-1.540</td>\n","      <td>26454</td>\n","      <td>480_540_198</td>\n","    </tr>\n","    <tr>\n","      <th>5237979</th>\n","      <td>199</td>\n","      <td>480</td>\n","      <td>540</td>\n","      <td>1.884e+06</td>\n","      <td>-1</td>\n","      <td>1.002</td>\n","      <td>2.407e+07</td>\n","      <td>1.001</td>\n","      <td>1.001</td>\n","      <td>1.002</td>\n","      <td>250081.44</td>\n","      <td>1.002</td>\n","      <td>300167.56</td>\n","      <td>1.002</td>\n","      <td>-6.530</td>\n","      <td>26454</td>\n","      <td>480_540_199</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5237980 rows √ó 17 columns</p>\n","</div>"],"text/plain":["         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n","0               0        0                  0       3.181e+06   \n","1               1        0                  0       1.666e+05   \n","2               2        0                  0       3.029e+05   \n","3               3        0                  0       1.192e+07   \n","4               4        0                  0       4.475e+05   \n","...           ...      ...                ...             ...   \n","5237975       195      480                540       2.441e+06   \n","5237976       196      480                540       3.495e+05   \n","5237977       197      480                540       0.000e+00   \n","5237978       198      480                540       1.001e+06   \n","5237979       199      480                540       1.884e+06   \n","\n","         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n","0                          1                1.000     1.338e+07        NaN   \n","1                         -1                1.000     1.642e+06        NaN   \n","2                         -1                1.000     1.819e+06        NaN   \n","3                         -1                1.000     1.839e+07        NaN   \n","4                         -1                1.000     1.786e+07        NaN   \n","...                      ...                  ...           ...        ...   \n","5237975                   -1                1.000     2.828e+07      1.000   \n","5237976                   -1                1.001     9.188e+06      1.000   \n","5237977                    0                0.996     1.273e+07      0.996   \n","5237978                    1                0.999     9.477e+07      0.999   \n","5237979                   -1                1.002     2.407e+07      1.001   \n","\n","         near_price  bid_price   bid_size  ask_price   ask_size    wap  \\\n","0               NaN      1.000   60651.50      1.000    8493.03  1.000   \n","1               NaN      1.000    3233.04      1.001   20605.09  1.000   \n","2               NaN      0.999   37956.00      1.000   18995.00  1.000   \n","3               NaN      1.000    2324.90      1.000  479032.40  1.000   \n","4               NaN      0.999   16485.54      1.000     434.10  1.000   \n","...             ...        ...        ...        ...        ...    ...   \n","5237975       1.000      1.000   32257.04      1.000  319862.40  1.000   \n","5237976       1.000      1.001  205108.40      1.001   93393.07  1.001   \n","5237977       0.996      0.996   16790.66      0.996  180038.32  0.996   \n","5237978       0.999      0.999  125631.72      0.999  669893.00  0.999   \n","5237979       1.001      1.002  250081.44      1.002  300167.56  1.002   \n","\n","         target  time_id       row_id  \n","0        -3.030        0        0_0_0  \n","1        -5.520        0        0_0_1  \n","2        -8.390        0        0_0_2  \n","3        -4.010        0        0_0_3  \n","4        -7.350        0        0_0_4  \n","...         ...      ...          ...  \n","5237975   2.310    26454  480_540_195  \n","5237976  -8.220    26454  480_540_196  \n","5237977   1.169    26454  480_540_197  \n","5237978  -1.540    26454  480_540_198  \n","5237979  -6.530    26454  480_540_199  \n","\n","[5237980 rows x 17 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["Xy_train = pd.read_csv(DATA_DIR + \"train.csv\")\n","Xy_train"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique</th>\n","      <th>cardinality</th>\n","      <th>with_null</th>\n","      <th>null_pct</th>\n","      <th>1st_row</th>\n","      <th>random_row</th>\n","      <th>last_row</th>\n","      <th>dtype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>stock_id</th>\n","      <td>False</td>\n","      <td>200</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>175</td>\n","      <td>199</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>date_id</th>\n","      <td>False</td>\n","      <td>481</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>365</td>\n","      <td>480</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>seconds_in_bucket</th>\n","      <td>False</td>\n","      <td>55</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>80</td>\n","      <td>540</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>imbalance_size</th>\n","      <td>False</td>\n","      <td>2971863</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>3180602.69</td>\n","      <td>36399479.86</td>\n","      <td>1884285.71</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>imbalance_buy_sell_flag</th>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>reference_price</th>\n","      <td>False</td>\n","      <td>28741</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.002</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>matched_size</th>\n","      <td>False</td>\n","      <td>2948862</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>13380276.64</td>\n","      <td>250147151.59</td>\n","      <td>24073677.32</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>far_price</th>\n","      <td>False</td>\n","      <td>95739</td>\n","      <td>True</td>\n","      <td>55.26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.001</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>near_price</th>\n","      <td>False</td>\n","      <td>84625</td>\n","      <td>True</td>\n","      <td>54.55</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.001</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>bid_price</th>\n","      <td>False</td>\n","      <td>28313</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.002</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>bid_size</th>\n","      <td>False</td>\n","      <td>2591773</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>60651.5</td>\n","      <td>92639.04</td>\n","      <td>250081.44</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>ask_price</th>\n","      <td>False</td>\n","      <td>28266</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.002</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>ask_size</th>\n","      <td>False</td>\n","      <td>2623254</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>8493.03</td>\n","      <td>83877.66</td>\n","      <td>300167.56</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>wap</th>\n","      <td>False</td>\n","      <td>31506</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.002</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <td>False</td>\n","      <td>15934</td>\n","      <td>True</td>\n","      <td>0.00</td>\n","      <td>-3.03</td>\n","      <td>-1.2</td>\n","      <td>-6.53</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>time_id</th>\n","      <td>False</td>\n","      <td>26455</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>20083</td>\n","      <td>26454</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>row_id</th>\n","      <td>True</td>\n","      <td>5237980</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0_0_0</td>\n","      <td>365_80_175</td>\n","      <td>480_540_199</td>\n","      <td>object</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      unique  cardinality  with_null  null_pct      1st_row  \\\n","stock_id               False          200      False      0.00            0   \n","date_id                False          481      False      0.00            0   \n","seconds_in_bucket      False           55      False      0.00            0   \n","imbalance_size         False      2971863       True      0.00   3180602.69   \n","imbalance_buy_sel...   False            3      False      0.00            1   \n","reference_price        False        28741       True      0.00          1.0   \n","matched_size           False      2948862       True      0.00  13380276.64   \n","far_price              False        95739       True     55.26          NaN   \n","near_price             False        84625       True     54.55          NaN   \n","bid_price              False        28313       True      0.00          1.0   \n","bid_size               False      2591773      False      0.00      60651.5   \n","ask_price              False        28266       True      0.00          1.0   \n","ask_size               False      2623254      False      0.00      8493.03   \n","wap                    False        31506       True      0.00          1.0   \n","target                 False        15934       True      0.00        -3.03   \n","time_id                False        26455      False      0.00            0   \n","row_id                  True      5237980      False      0.00        0_0_0   \n","\n","                        random_row     last_row    dtype  \n","stock_id                       175          199    int64  \n","date_id                        365          480    int64  \n","seconds_in_bucket               80          540    int64  \n","imbalance_size         36399479.86   1884285.71  float64  \n","imbalance_buy_sel...             1           -1    int64  \n","reference_price                1.0        1.002  float64  \n","matched_size          250147151.59  24073677.32  float64  \n","far_price                      NaN        1.001  float64  \n","near_price                     NaN        1.001  float64  \n","bid_price                      1.0        1.002  float64  \n","bid_size                  92639.04    250081.44  float64  \n","ask_price                      1.0        1.002  float64  \n","ask_size                  83877.66    300167.56  float64  \n","wap                            1.0        1.002  float64  \n","target                        -1.2        -6.53  float64  \n","time_id                      20083        26454    int64  \n","row_id                  365_80_175  480_540_199   object  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["inspect_columns(Xy_train)"]},{"cell_type":"markdown","metadata":{},"source":["The following guesses could be made, based on the glimpse of the data:\n","\n","- 200 \\* 481 \\* 55 = 5,291,000, which is roughly equal to the number of total rows. We assume that\n","\n","    - The training data consist of 200 * 481 = 96,200 time series;\n","\n","    - Each time series are 55 steps long, and each time series represents the last 10 mins of a given stock on a given trading date.\n","\n","- 5,291,000 - 5,237,980 = 53,020, so there are some data missing. \n","\n","    - It's normal, as explained in the [Dataset Description](https://www.kaggle.com/competitions/optiver-trading-at-the-close/data): _Not all stock IDs exist in every time bucket_.\n","\n","    - We will further explore what kind of data missing are we facing here.\n","\n","- 481 * 55 = 26,455, so `time_id` is just a new id for the permutation of `seconds_in_bucket` and `date_id`.\n","\n","- `row_id` is a string concatenation of `date_id`, `seconds_in_bucket`, and `stock_id`, separated with underscores.\n","\n","- `target` is the **target** variable we want to predict, for its namesake.\n","\n","- Other columns are the **features** (or **covariate** in terms of Time Series ML)."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>seconds_in_bucket</th>\n","      <th>imbalance_size</th>\n","      <th>imbalance_buy_sell_flag</th>\n","      <th>reference_price</th>\n","      <th>matched_size</th>\n","      <th>far_price</th>\n","      <th>near_price</th>\n","      <th>bid_price</th>\n","      <th>bid_size</th>\n","      <th>ask_price</th>\n","      <th>ask_size</th>\n","      <th>wap</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42026</th>\n","      <td>0</td>\n","      <td>126061.42</td>\n","      <td>-1</td>\n","      <td>1.000</td>\n","      <td>4.550e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000</td>\n","      <td>1443.36</td>\n","      <td>1.001</td>\n","      <td>29387.97</td>\n","      <td>1.000</td>\n","      <td>-7.84</td>\n","    </tr>\n","    <tr>\n","      <th>42218</th>\n","      <td>10</td>\n","      <td>70729.12</td>\n","      <td>-1</td>\n","      <td>0.999</td>\n","      <td>4.605e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.998</td>\n","      <td>48012.00</td>\n","      <td>1.000</td>\n","      <td>48095.00</td>\n","      <td>0.999</td>\n","      <td>5.97</td>\n","    </tr>\n","    <tr>\n","      <th>42410</th>\n","      <td>20</td>\n","      <td>65917.61</td>\n","      <td>-1</td>\n","      <td>0.999</td>\n","      <td>4.610e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.998</td>\n","      <td>480.13</td>\n","      <td>1.000</td>\n","      <td>48095.00</td>\n","      <td>0.998</td>\n","      <td>16.19</td>\n","    </tr>\n","    <tr>\n","      <th>42602</th>\n","      <td>30</td>\n","      <td>100079.30</td>\n","      <td>-1</td>\n","      <td>0.998</td>\n","      <td>4.610e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.998</td>\n","      <td>48014.00</td>\n","      <td>1.000</td>\n","      <td>15870.03</td>\n","      <td>0.999</td>\n","      <td>2.18</td>\n","    </tr>\n","    <tr>\n","      <th>42794</th>\n","      <td>40</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.710e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>6727.70</td>\n","      <td>1.000</td>\n","      <td>2887.32</td>\n","      <td>1.000</td>\n","      <td>-4.70</td>\n","    </tr>\n","    <tr>\n","      <th>42986</th>\n","      <td>50</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.710e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>14417.40</td>\n","      <td>1.000</td>\n","      <td>4811.80</td>\n","      <td>1.000</td>\n","      <td>-2.91</td>\n","    </tr>\n","    <tr>\n","      <th>43178</th>\n","      <td>60</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.710e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>4805.80</td>\n","      <td>1.000</td>\n","      <td>5292.98</td>\n","      <td>0.999</td>\n","      <td>-14.79</td>\n","    </tr>\n","    <tr>\n","      <th>43370</th>\n","      <td>70</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.713e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>4805.80</td>\n","      <td>1.000</td>\n","      <td>5292.98</td>\n","      <td>0.999</td>\n","      <td>-12.59</td>\n","    </tr>\n","    <tr>\n","      <th>43562</th>\n","      <td>80</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.713e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>4805.80</td>\n","      <td>1.000</td>\n","      <td>5292.98</td>\n","      <td>0.999</td>\n","      <td>-5.46</td>\n","    </tr>\n","    <tr>\n","      <th>43754</th>\n","      <td>90</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.999</td>\n","      <td>4.713e+06</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.999</td>\n","      <td>4805.80</td>\n","      <td>1.000</td>\n","      <td>7698.88</td>\n","      <td>0.999</td>\n","      <td>-10.62</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       seconds_in_bucket  imbalance_size  imbalance_buy_sell_flag  \\\n","42026                  0       126061.42                   -1       \n","42218                 10        70729.12                   -1       \n","42410                 20        65917.61                   -1       \n","42602                 30       100079.30                   -1       \n","42794                 40            0.00                    0       \n","42986                 50            0.00                    0       \n","43178                 60            0.00                    0       \n","43370                 70            0.00                    0       \n","43562                 80            0.00                    0       \n","43754                 90            0.00                    0       \n","\n","       reference_price  matched_size  far_price  near_price  bid_price  \\\n","42026            1.000     4.550e+06        NaN         NaN      1.000   \n","42218            0.999     4.605e+06        NaN         NaN      0.998   \n","42410            0.999     4.610e+06        NaN         NaN      0.998   \n","42602            0.998     4.610e+06        NaN         NaN      0.998   \n","42794            0.999     4.710e+06        NaN         NaN      0.999   \n","42986            0.999     4.710e+06        NaN         NaN      0.999   \n","43178            0.999     4.710e+06        NaN         NaN      0.999   \n","43370            0.999     4.713e+06        NaN         NaN      0.999   \n","43562            0.999     4.713e+06        NaN         NaN      0.999   \n","43754            0.999     4.713e+06        NaN         NaN      0.999   \n","\n","       bid_size  ask_price  ask_size    wap  target  \n","42026   1443.36      1.001  29387.97  1.000   -7.84  \n","42218  48012.00      1.000  48095.00  0.999    5.97  \n","42410    480.13      1.000  48095.00  0.998   16.19  \n","42602  48014.00      1.000  15870.03  0.999    2.18  \n","42794   6727.70      1.000   2887.32  1.000   -4.70  \n","42986  14417.40      1.000   4811.80  1.000   -2.91  \n","43178   4805.80      1.000   5292.98  0.999  -14.79  \n","43370   4805.80      1.000   5292.98  0.999  -12.59  \n","43562   4805.80      1.000   5292.98  0.999   -5.46  \n","43754   4805.80      1.000   7698.88  0.999  -10.62  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Take a look at any single time series by setting the stock_id and date_id\n","\n","stock_id = 6\n","date_id = 4\n","\n","(Xy_train\n","    .query(f'stock_id == {stock_id} & date_id == {date_id}')\n","    .drop(columns=['stock_id', 'date_id', 'time_id', 'row_id'])\n","    .head(10)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1.2. What type of data missing?"]},{"cell_type":"markdown","metadata":{},"source":["There are 3 types of data missing in the world of Time Series:\n","\n","1. Are there some time series are missing entirely (e.g., some stocks have no data at all on some days)? \n","\n","2. Are some time series are missing their steps (e.g., some time series have steps less than 55)?\n","\n","3. Both?\n","\n","**The answer to these questions are crucial to our later model building.**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's first exam if all the time series are 55 steps long\n","\n","(Xy_train\n","    .groupby(['stock_id', 'date_id'])\n","    ['seconds_in_bucket'] # Extract the column of interest\n","    .count() # Count the number of rows in each permutation of stock_id and date_id\n","    .apply(lambda x: x == 55) # Check if every count is 55\n","    .all() # Check if all the booleans are True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["The above result suggests that all the time series in our training data are of the same length of 55.\n","\n","Therefore, it can be concluded that **there are some stocks missing data on some days entirely**.\n","\n","phew! That's a relief.\n","\n","From my past experiences, many time series each with a few irregular lose steps are way harder to deal with than a few time series missing entirely while other time series are whole.\n","\n","Fortunately, that kind of problem is not the case here. \n","\n","Next, let's keep exploring which stocks are missing data on which days?"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 3 4 5 6 7 8 9]\n","[190 191 192 193 194 195 196 197 198 199]\n"]}],"source":["all_stock_id = np.sort(Xy_train[\"stock_id\"].unique())\n","print(all_stock_id[:10])\n","print(all_stock_id[-10:])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 3 4 5 6 7 8 9]\n","[471 472 473 474 475 476 477 478 479 480]\n"]}],"source":["all_date_id = np.sort(Xy_train[\"date_id\"].unique())\n","print(all_date_id[:10])\n","print(all_date_id[-10:])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["stock_id\n","69       0\n","78       0\n","79       0\n","102      0\n","135      0\n","      ... \n","102    291\n","102    292\n","102    293\n","102    294\n","73     320\n","Name: date_id, Length: 964, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Make a MultiIndex object from the cartesian product of all possible combinations.\n","multi_index = pd.MultiIndex.from_product(\n","    iterables=[all_date_id, all_stock_id], \n","    names=[\"date_id\", \"stock_id\"]\n",")\n","\n","# To get the all missing data.\n","# join the MultiIndex with the Trianing data,\n","# and then filter out all the rows that are not in the training data.\n","missing_data = (Xy_train\n","    .loc[:, [\"date_id\", \"stock_id\"]]\n","    .assign(in_train=True) # Add a new column to indicate if the row is in the training data\n","    .set_index([\"date_id\", \"stock_id\"])\n","    .merge(multi_index.to_frame(), how=\"right\", left_index=True, right_index=True)\n","    .query(\"in_train.isna()\") # Filter out the missing data\n","    .set_index(\"stock_id\", drop=True)\n","    [\"date_id\"]\n",")\n","\n","# A Series object for missing data\n","missing_data"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["MultiIndex([(  0,   0),\n","            (  0,   1),\n","            (  0,   2),\n","            (  0,   3),\n","            (  0,   4),\n","            (  0,   5),\n","            (  0,   6),\n","            (  0,   7),\n","            (  0,   8),\n","            (  0,   9),\n","            ...\n","            (480, 190),\n","            (480, 191),\n","            (480, 192),\n","            (480, 193),\n","            (480, 194),\n","            (480, 195),\n","            (480, 196),\n","            (480, 197),\n","            (480, 198),\n","            (480, 199)],\n","           names=['date_id', 'stock_id'], length=96200)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["multi_index"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Show all the stock_id that have at least 1 day of missing data\n","missing_data.index.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# See which date's data are missing for a specific stock_id\n","stock_id = 78 # change this\n","missing_data[stock_id]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# A summary of the of missing date counts for each stock_id\n","missing_data.groupby(\"stock_id\").count().sort_values()"]},{"cell_type":"markdown","metadata":{},"source":["`stock_id = 73` is missing 1 day of data, and `stock_id = 102` is missing 295 days of data, and so forth."]},{"cell_type":"markdown","metadata":{},"source":["## 1.2. Understand the features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def time_series_plot(df, cols, stock_id, date_id):\n","    # A helper function to plot the time seires for a given stock in a given date\n","    (df\n","        .query(f'stock_id == {stock_id} & date_id == {date_id}')\n","        .loc[:, ['seconds_in_bucket'] + cols]\n","        # .replace(0, np.nan)\n","        .set_index('seconds_in_bucket')\n","        .plot(title=f'Stock {stock_id} on Day {date_id}', figsize=(10, 4), linewidth=1)\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2.1 Order book\n","\n","We need to first understand the concept of **Order book** to understand following features:\n","\n","- `bid_price`\n","- `ask_price`\n","- `bid_size`\n","- `ask_size`\n","- `wap`\n","\n","So, what is an order book?\n","\n","![](https://i.ibb.co/sqVfdLm/order-book-1.png)\n","\n","Above picture is a demo of an Order Book,\n","\n","- We can see that at a price level of 9 there are 2 shares on the **bid**, meaning the market participants are willing to **buy** 2 shares for a price of 9.\n","\n","- We can also see that at a price level of 10 there is 1 share on the **ask**, meaning market participants are willing to **sell** 1 share for a price of 10.\n","\n","![](https://i.ibb.co/WHMX37t/order-book-2.png)\n","\n","If someone were to put in an ask of 10 shares at a price of 9, then 2 shares would be **matched**. The new best ask would be 8 shares at a price of 9, the new state of the book is displayed above.\n","\n","-----\n","\n","According to the [Dataset Description](https://www.kaggle.com/competitions/optiver-trading-at-the-close/data):\n","\n","- `bid_price` & `ask_price` - Price of the most competitive buy/sell level in the non-auction book.\n","\n","- `bid_size` & `ask_size` - The _dollar notional_ amount on the most competitive buy/sell level in the non-auction book.\n","\n","- `wap` - The weighted average price in the non-auction book.\n","\n","$$\n","\\frac{ {BidPrice * AskSize + AskPrice * BidSize}}{BidSize + AskSize}\n","$$\n","\n","Other than `wap`, the other 4 features are self-explanatory.\n","\n","To understand `wap` _intuitively_, we have did some researches on the formula and found the following properties:\n","\n","- `wap` is always larger than `bid_price` and smaller `ask_price`.\n","\n","- If `bid_size` is larger than `ask_size`, then `wap` would be closer to `ask_price`, and vice versa.\n","\n","In other words, an increase in `bid_size` / `ask_size` would \"push\" the `wap` toward opposite direction, but `wap` would always stays in the gap between `bid_price` and `ask_price`.\n","\n","**Basically, `wap` serve as a decent guess of the _fair price_ of a stock**: If the `bid_size` increase, the buyers are more aggressive, so the _fair price_ should be closer to the `ask_price`. It makes intuitive sense, right?\n","\n","Now we draw some time series plots to confirm our speculations:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# We tried a few different stock_id and date_id to see the common patterns\n","\n","time_series_plot(\n","    df=Xy_train, \n","    cols=['bid_price','ask_price', 'wap'], \n","    stock_id = 1,\n","    date_id = 10\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Another example\n","\n","time_series_plot(\n","    df=Xy_train, \n","    cols=['bid_price','ask_price', 'wap'], \n","    stock_id = 10,\n","    date_id = 100\n",")"]},{"cell_type":"markdown","metadata":{},"source":["And one more thing, all the prices shown here are converted to a price move relative to the stock `wap` (weighted average price) at the beginning of the auction period."]},{"cell_type":"markdown","metadata":{},"source":["### 1.2.2. Auction Order Book\n","\n","The concept of **Auction Order Book** is the key to understand the follwoing features:\n","\n","- `imbalance_size`\n","- `imbalance_buy_sell_flag`\n","- `matched_size`\n","- `far_price`\n","\n","So, what is an Auction Order Book? And how it differ from an (oridinary) Order Book?\n","\n","**In an Auction Order Book, the orders are not immediately matched, but instead collected until the moment the auction ends.**\n","\n","![](https://i.ibb.co/HFjZQV9/order-book-3.png)\n","\n","In the above example, the book is referred to as **in cross**, since the best bid and ask are overlapping.\n","\n","Suppose the auction ends with the book in this state, then:\n","\n","- At a price of 10, 0 lots would be matched since there as no bids >= 10.\n","\n","- At a price of 9, 3 lots would be matched, as there are 3 bids >=9 and 6 asks <= 9.\n","\n","- At a price of 8, 4 lots would be matched, since are 7 bids>=8, and there are 4 asks<=8.\n","\n","So the price which _maximizes_ the number of matched lots would be 8. In the situation like this, We would describe the Auction Order Nook in the following way:\n","\n","- The **uncross price** is 8\n","- The **matched size** would be 4\n","- There are 3 Bids (7 - 4 = 3) are still unmatched, therefore, the **imbalance** would be 3 lots in the buy direction.\n","\n","At any given time, the hypothetical **uncross price** (assuming the auction ends immediately) is defined as the current **far price**. \n","\n","In other words, the **far price** is the price which _maximizes_ the number of matched lots in current status of the Auction Order Book.\n","\n","Nasdaq provides **far price** information 5 minutes before the closing cross (3:55 p.m.).\n","\n","Describe the above situtation in terms of our \"features\", that would be: \n","\n","- `far_price` = 8\n","- `matched_size` = 4 * `reference price` (we will explain `reference price` later)\n","- `imbalance_size` = 3 * `reference price`\n","- `imbalance_buy_sell_flag` = 1 (1 for buy-side imbalance, -1 for sell-side imbalance, 0 for no imbalance)\n","\n","Now let's plot some time series:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# To see different random stock_id and date_id, simply run the cell again\n","time_series_plot(\n","    df=Xy_train, \n","    cols=['imbalance_buy_sell_flag'], \n","    stock_id = np.random.randint(low=0, high=200), \n","    date_id = np.random.randint(low=0, high=480),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare the far_price and wap\n","time_series_plot(\n","    df=Xy_train, \n","    cols=['far_price', 'wap'],\n","    stock_id = np.random.randint(low=0, high=200), \n","    date_id = np.random.randint(low=0, high=480),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare the matched_size and imbalance_size\n","time_series_plot(\n","    df=Xy_train, \n","    cols=['matched_size', 'imbalance_size'], \n","    stock_id = np.random.randint(low=0, high=200), \n","    date_id = np.random.randint(low=0, high=480),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["After plotting the time series for different stock_id and date_id for serval times, we observe a few patterns:\n","\n","- `Far Price` shows data only after `second_in_bucket`=300, which corresponds to 3:55 p.m.\n","\n","- `matched_size` and `imbalance_size` significantly diverge at size, after `second_in_bucket`=240 (3:54 p.m.); `imbalance_size` tends to decrease, and `matched_size` tends to increase, after this time point."]},{"cell_type":"markdown","metadata":{},"source":["### 1.2.3. Combined Book\n","\n","Finally, the rest 2 features are related to the **Combined Book**, which is the combination of **Order Book** and **Auction Order Book**.\n","\n","- `reference_price`\n","- `near_price`\n","\n","Here we combine our previous order book example & auction book example by aggregating the buying & selling interest across all price levels.\n","\n","![](https://i.ibb.co/1vPFYwz/order-book-4.png)\n","\n","For this combined book:\n","\n","- At a price of 10, 0 lots would be matched, as there are no bids>=10.\n","\n","- At a price of 9, 5 lots would be matched, as there are 5 bids>=9 and 6 asks <=9.\n","\n","- At a price of 8, 4 lots would be matched, as there are 9 bids>=8 and 4 asks <=8.\n","\n","So, the price which maximizes matched lots would be the price of 9. We would therefore describe the combined order book in the following way:\n","\n","- The uncross price is 9\n","- The matched size is 5\n","- The imbalance would be 1 lot, in the sell direction.\n","\n","The hypothetical uncross price of combined book is called the **near price**. \n","\n","Same as the **far price**, Nasdaq provides **near price** 5 minutes before the closing cross (3:55 p.m.).\n","\n","Nasdaq also provides an indication of the fair price called the **reference price**. The reference price is calculated as follows:\n","\n","- If the near price is between the best bid and ask, then the reference price is equal to the near price\n","\n","- If the near price > best ask, then reference price = best ask\n","\n","- If the near price < best bid, then reference price = best bid So the reference price is the near price bounded between the best bid and ask.\n","\n","Now let's put the `bid_price`, `ask_price`, `wap`, `far_price`, `near_price`, and `reference_price` together:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["time_series_plot(\n","    df=Xy_train, \n","    cols=['bid_price', 'ask_price', 'wap', 'far_price', 'near_price', 'reference_price'], \n","    stock_id = np.random.randint(low=0, high=200), \n","    date_id = np.random.randint(low=0, high=480),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Finally, according to the [Dataset Description](https://www.kaggle.com/competitions/optiver-trading-at-the-close/data), all price related columns are converted to a price move relative to the stock `wap` at the beginning of the auction period. \n","\n","In other words, the `wap` should be 1 for all beginnings of our Time Series. Let's verify this programatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find all wap not equal 1 when seconds_in_bucket == 0\n","Xy_train.query(\"seconds_in_bucket == 0\").query('wap != 1')"]},{"cell_type":"markdown","metadata":{},"source":["Only 4 time series do not have `wap` equal to 1 at the beginning. \n","\n","And after we examine them one by one, we found that their `wap` are all NA."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's verify the above statement programmatically\n","\n","ts1 = Xy_train.query(\"stock_id == 131 & date_id == 35\")[\"wap\"]\n","ts2 = Xy_train.query(\"stock_id == 101 & date_id == 328\")[\"wap\"]\n","ts3 = Xy_train.query(\"stock_id == 158 & date_id == 388\")[\"wap\"]\n","ts4 = Xy_train.query(\"stock_id == 19 & date_id == 438\")[\"wap\"]\n","\n","pd.concat([ts1, ts2, ts3, ts4], axis=0).isna().all()"]},{"cell_type":"markdown","metadata":{},"source":["## 1.3 Understand the target (WIP üë∑)\n","\n","> According to the [Dataset Description](https://www.kaggle.com/competitions/optiver-trading-at-the-close/data), `target` is the 60 second future move in the `wap` of the stock, less the 60 second future move of the synthetic index."]},{"cell_type":"markdown","metadata":{},"source":["# 2. LightGBM Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# We split the data here, and use them in the following sections\n","\n","X_train = Xy_train.query(\"target.notna()\").drop(['row_id', \"time_id\"], axis=1)\n","y_train = X_train.pop(\"target\")"]},{"cell_type":"markdown","metadata":{},"source":["## 2.1. Naive Baseline"]},{"cell_type":"markdown","metadata":{},"source":["The following code submit a prediction that all target = 0. \n","\n","To understand how the submission API work, jump to the final section of this notebook."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'optiver2023.competition'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\87489\\OneDrive\\ÊñáÊ°£\\GitHub\\Kaggle_Optiver_2023\\explain-the-data-lightgbm-baseline.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/87489/OneDrive/%E6%96%87%E6%A1%A3/GitHub/Kaggle_Optiver_2023/explain-the-data-lightgbm-baseline.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptiver2023\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/87489/OneDrive/%E6%96%87%E6%A1%A3/GitHub/Kaggle_Optiver_2023/explain-the-data-lightgbm-baseline.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m env \u001b[39m=\u001b[39m optiver2023\u001b[39m.\u001b[39mmake_env()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/87489/OneDrive/%E6%96%87%E6%A1%A3/GitHub/Kaggle_Optiver_2023/explain-the-data-lightgbm-baseline.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m iter_test \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39miter_test()\n","File \u001b[1;32mc:\\Users\\87489\\OneDrive\\ÊñáÊ°£\\GitHub\\Kaggle_Optiver_2023\\optiver2023\\__init__.py:2\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompetition\u001b[39;00m \u001b[39mimport\u001b[39;00m make_env\n\u001b[0;32m      4\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mmake_env\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optiver2023.competition'"]}],"source":["# import optiver2023\n","\n","# env = optiver2023.make_env()\n","# iter_test = env.iter_test()\n","\n","# counter = 0\n","# for (test, revealed_targets, sample_prediction) in iter_test:\n","#     sample_prediction['target'] = 0\n","#     env.predict(sample_prediction)\n","#     counter += 1"]},{"cell_type":"markdown","metadata":{},"source":["The Naive Forecast submission yields a **score of 5.465** (2023-09-25).\n","\n","As of 2023-09-25, the 1st best score on the Leaderboard is 5.3441 and the 10th best score is 5.3706.\n","\n","Could the small gap between the score of our Naive Forecast and the Best score on the Leaderboard suggest that the data are of low predictability?"]},{"cell_type":"markdown","metadata":{},"source":["## 2.2. Simplest LightGBM Solution"]},{"cell_type":"markdown","metadata":{},"source":["Here, we aim to provide a valid LightGBM solution using as few lines of code as possible. To see if it beats the Naive baseline."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# env = optiver2023.make_env()\n","# iter_test = env.iter_test()\n","\n","# model = lightgbm.LGBMRegressor(\n","#     random_state = SEED, \n","#     objective = 'mae', \n","#     device_type = 'gpu'\n","# )\n","\n","# model.fit(X_train, y_train)\n","\n","# counter = 0\n","# for (test, revealed_targets, sample_prediction) in iter_test:\n","#     sample_prediction['target'] = model.predict(test.drop('row_id', axis = 1))\n","#     env.predict(sample_prediction)\n","#     counter += 1"]},{"cell_type":"markdown","metadata":{},"source":["The LightGBM Baseline submission yields a **score of 5.4209** (2023-09-25).\n","\n","- 5.465 - 5.4209 = 0.0441 (Baseline LightGBM imporved the score from Naive by 0.0441)\n","\n","- 5.465 - 5.3706 = 0.0944 (10th best score on the Leaderboard imporved the score by 0.0944)\n","\n","- 5.465 - 5.3441 = 0.1209 (1st best score on the Leaderboard imporved the score by 0.1209)\n","\n","Still a long way to go..."]},{"cell_type":"markdown","metadata":{},"source":["## 2.3. Improved LightGBM Solution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def calculate_imbalance_features(df):\n","#     # Calculate and add imbalance feature 1 (imb_s1)\n","#     df['imb_s1'] = df.eval('(bid_size - ask_size) / (bid_size + ask_size)')  \n","\n","#     # Calculate and add imbalance feature 2 (imb_s2)\n","#     df['imb_s2'] = df.eval('(imbalance_size - matched_size) / (matched_size + imbalance_size)') \n","\n","#     return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# estimator = lightgbm.LGBMRegressor(\n","#     boosting_type='gbdt', \n","#     num_leaves=31, \n","#     max_depth=-1, \n","#     learning_rate=0.1, \n","#     n_estimators=100, \n","#     subsample_for_bin=200000, \n","#     objective='mae', \n","#     class_weight=None, \n","#     min_split_gain=0.0, \n","#     min_child_weight=0.001, \n","#     min_child_samples=20, \n","#     subsample=1.0, \n","#     subsample_freq=0, \n","#     colsample_bytree=1.0, \n","#     reg_alpha=0.0, \n","#     reg_lambda=0.0, \n","#     random_state=SEED, \n","#     n_jobs=-1, \n","#     importance_type='split',\n","#     force_row_wise=True\n","# )\n","\n","# val_predictions = np.zeros(len(X_train))\n","# val_scores = []\n","\n","# splitter = sk.model_selection.TimeSeriesSplit(5).split(X_train, y_train)\n","\n","# for fold, (train_idx, val_idx) in enumerate(splitter):\n","#     model = sk.base.clone(estimator)\n","\n","#     # Define train and val set\n","#     X_train = X_train.iloc[train_idx]\n","#     y_train = y_train.iloc[train_idx]\n","#     X_val = X_train.iloc[val_idx]\n","#     y_val = y_train.iloc[val_idx]\n","\n","#     model.fit(X_train, y_train)\n","#     val_scores.append(sk.metrics.mean_absolute_error(model.predict(X_val), y_val))\n","\n","# print(f'Val Score: {np.mean(val_scores):.2f} ¬± {np.std(val_scores):.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import optiver2023\n","\n","# env = optiver2023.make_env()\n","# iter_test = env.iter_test()\n","\n","# model.fit(X_train, y_train)\n","\n","# counter = 0\n","# for (test, revealed_targets, sample_prediction) in iter_test:\n","#     sample_prediction['target'] = model.predict(test.drop('row_id', axis = 1))\n","#     env.predict(sample_prediction)\n","#     counter += 1"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Final Thoughts"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["END = pd.Timestamp.now()\n","time_elapsed = (END - START).total_seconds()\n","print(f\"Notebook Total Time: {time_elapsed:.2f}s\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
