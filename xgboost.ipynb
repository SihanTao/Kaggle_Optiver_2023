{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "file = pd.read_csv('train.csv')\n",
    "file.drop([\"date_id\",\"seconds_in_bucket\",\"row_id\"], axis=1, inplace=True)\n",
    "stock_id_list = []\n",
    "for stock_id, df in file.groupby(['stock_id']):\n",
    "    ## fill the missing far_price values with the mean of the far_price\n",
    "    df['far_price'].fillna(df['far_price'].mean(), inplace=True)\n",
    "    df['near_price'].fillna(df['near_price'].mean(), inplace=True)\n",
    "    df = df[['stock_id', 'imbalance_size', 'imbalance_buy_sell_flag','reference_price', 'matched_size', 'far_price', 'near_price','bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'time_id','target']]\n",
    "    \n",
    "    if len(df) < 26455:\n",
    "        continue\n",
    "    else:\n",
    "        stock_id_list.append(df)\n",
    "\n",
    "## change the stock_id_list dimension to (time,stock_id, 13)\n",
    "\n",
    "stock_id_list = np.array(stock_id_list).astype(np.float32) ## (stock_id,time,13) \n",
    "features = stock_id_list[:,:,:-1]\n",
    "target = stock_id_list[:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgmodel(features=features,target=target):\n",
    "    mask = ~np.isnan(target).any(axis=1)\n",
    "    features = features[mask]\n",
    "    target = target[mask]\n",
    "\n",
    "    def break_into_subsequences_with_padding(data, target, length):\n",
    "        subsequences = []\n",
    "        subtargets = []\n",
    "        total_sequences = data.shape[1] // length\n",
    "        for i in range(total_sequences):\n",
    "            subsequences.append(data[:, i*length:(i+1)*length])\n",
    "            subtargets.append(target[:, i*length:(i+1)*length])\n",
    "        \n",
    "        # Handle the last subsequence which might need padding\n",
    "        if data.shape[1] % length != 0:\n",
    "            padding_size = length - data.shape[1] % length\n",
    "            start_idx = total_sequences * length  # start index for the last subsequence\n",
    "            last_subseq = np.pad(data[:, start_idx:], ((0,0), (0, padding_size), (0,0)), mode='constant')\n",
    "            last_target = np.pad(target[:, start_idx:], ((0,0), (0, padding_size)), mode='constant')\n",
    "            subsequences.append(last_subseq)\n",
    "            subtargets.append(last_target)\n",
    "        \n",
    "        return np.concatenate(subsequences, axis=0), np.concatenate(subtargets, axis=0)\n",
    "\n",
    "    # Define the subsequence length\n",
    "    subseq_length = 256  # for example\n",
    "\n",
    "    # Break sequences into smaller subsequences and pad if necessary\n",
    "    features_subseq, target_subseq = break_into_subsequences_with_padding(features, target, subseq_length)\n",
    "    features = features_subseq\n",
    "    target = target_subseq\n",
    "    \n",
    "    features_2d = features.reshape(-1, features.shape[-1])\n",
    "    target_2d = target.reshape(-1)\n",
    "\n",
    "    # Combine into a single DataFrame\n",
    "    data = pd.DataFrame(features_2d)\n",
    "    data['target'] = target_2d\n",
    "\n",
    "    # Drop rows where 'target' is NaN\n",
    "    data = data.dropna(subset=['target'])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train XGBoost model, using MAE as the objective function\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', reg_alpha=0.5)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'MAE: {mae:.4f}')\n",
    "    \n",
    "\n",
    "    test_features_2d = test_features.reshape(-1, test_features.shape[-1])\n",
    "    test_data = pd.DataFrame(test_features_2d)\n",
    "    # Predict using the trained model\n",
    "    y_pred = model.predict(test_data)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.1146\n"
     ]
    }
   ],
   "source": [
    "xg_pred = xgmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4845071 ,  0.04586141,  1.0194033 , ..., -0.01175968,\n",
       "        0.00138574, -0.14717986], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
